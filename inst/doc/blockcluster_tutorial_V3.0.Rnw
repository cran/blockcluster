%\VignetteIndexEntry{blockcluster tutorial}

\documentclass[a4paper,11pt]{article}
\usepackage[utf8x]{inputenc}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{rotating}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage[toc,page]{appendix}
\usepackage{tikz}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations.markings}
\usepackage{amsfonts,amstext,amsmath,amssymb}
\usepackage{array}
%% Bibliography
%\usepackage{natbib}
\usepackage{fullpage}
\usepackage{color}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

% une couleur par auteur lors de la redaction
\newcommand{\cb}[1]{{\color{blue}{{\bf CB:} #1}}}
\newcommand{\fl}[1]{{\color{red}{{\bf FL:} #1}}}

\lstset{
    language=R,
    basicstyle=\footnotesize\ttfamily,
    keywordstyle=\color{blue},
    commentstyle=\ttfamily\color{dkgreen},
    backgroundcolor=\color{white},
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2,
    captionpos=b,
    breaklines=true,
    breakatwhitespace=false,
    title=\lstname,
    escapeinside={},
    keywordstyle={},
    morekeywords={}
    }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Diverses commandes

\newcommand{\R}{\mathbb{R}}
\newcommand{\Rd}{\mathbb{R}^d}
\newcommand{\Xd}{\mathbb{X}^d}

% Diverses commandes
\newcommand{\calA}{{\cal A}}
\newcommand{\calB}{{\cal B}}
\newcommand{\calE}{{\cal E}}
\newcommand{\calF}{{\cal F}}
\newcommand{\calM}{{\cal M}}
\newcommand{\calN}{{\cal N}}
\newcommand{\calP}{{\cal P}}
\newcommand{\calT}{{\cal T}}
\newcommand{\calU}{{\cal U}}
\newcommand{\calW}{{\cal W}}
\newcommand{\calX}{{\cal X}}
\newcommand{\calZ}{{\cal Z}}


% Lettre ou chiffe en gras
\newcommand{\un}{\mathbf{1}}
\newcommand{\ba}{\mathbf{a}}
\newcommand{\bb}{\mathbf{b}}
\newcommand{\bc}{\mathbf{c}}
\newcommand{\bd}{\mathbf{d}}
\newcommand{\bg}{\mathbf{g}}
\newcommand{\bh}{\mathbf{h}}
\newcommand{\be}{\mathbf{e}}
\newcommand{\bL}{\mathbf{L}}
\newcommand{\bn}{\mathbf{n}}
\newcommand{\bp}{\mathbf{p}}
\newcommand{\bq}{\mathbf{q}}
\newcommand{\br}{\mathbf{r}}
\newcommand{\bs}{\mathbf{s}}
\newcommand{\bt}{\mathbf{t}}
\newcommand{\bu}{\mathbf{u}}
\newcommand{\bv}{\mathbf{v}}
\newcommand{\bW}{\mathbf{W}}
\newcommand{\bw}{\mathbf{w}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\bsx}{\boldsymbol{x}}
\newcommand{\bX}{\mathbf{X}}
\newcommand{\bsX}{\boldsymbol{X}}
\newcommand{\by}{\mathbf{y}}
\newcommand{\bsy}{\boldsymbol{y}}
\newcommand{\bY}{\mathbf{Y}}
\newcommand{\bsY}{\boldsymbol{Y}}
\newcommand{\bZ}{\mathbf{Z}}
\newcommand{\bz}{\mathbf{z}}

% Lettre grecque en gras % requiert \usepackage{amsbsy}
\newcommand{\balpha}{\boldsymbol{\alpha}}
\newcommand{\bbeta}{\boldsymbol{\beta}}
\newcommand{\bchi}{\boldsymbol{\chi}}
\newcommand{\bdelta}{\boldsymbol{\delta}}
\newcommand{\bDelta}{\boldsymbol{\Delta}}
\newcommand{\bepsilon}{\boldsymbol{\epsilon}}
\newcommand{\bGamma}{\boldsymbol{\Gamma}}
\newcommand{\bgamma}{\boldsymbol{\gamma}}
\newcommand{\blambda}{\boldsymbol{\lambda}}
\newcommand{\bkappa}{\boldsymbol{\kappa}}
\newcommand{\bmu}{\boldsymbol{\mu}}
\newcommand{\bnu}{\boldsymbol{\nu}}
\newcommand{\bpi}{\boldsymbol{\pi}}
\newcommand{\bphi}{\boldsymbol{\phi}}
\newcommand{\brho}{\boldsymbol{\rho}}
\newcommand{\bsigma}{\boldsymbol{\sigma}}
\newcommand{\bSigma}{\boldsymbol{\Sigma}}
\newcommand{\btheta}{\boldsymbol{\theta}}
\newcommand{\bTheta}{\boldsymbol{\Theta}}
\newcommand{\bvarepsilon}{\boldsymbol{\varepsilon}}
\newcommand{\bxi}{\boldsymbol{\xi}}


% Lettre verticale en gras  % requiert \usepackage{amsbsy}
\newcommand{\ve}[1]{{\boldsymbol{#1}}}
\newcommand{\x}{\boldsymbol{x}}
\newcommand{\X}{\boldsymbol{X}}
\newcommand{\z}{\boldsymbol{z}}
\newcommand{\Z}{\boldsymbol{Z}}


\newcommand{\argmin}{\mathop{\mathrm{argmin}}}
\newcommand{\argmax}{\mathop{\mathrm{argmax}}}
\newcommand{\trace}{\mathop{\mathrm{Tr}}}
\newcommand{\diag}{\mathop{\mathrm{diag}}}
\newcommand{\mix}{\textsc{mixmod}}
\newcommand{\II}{1 \! \! 1}
\newcommand{\IR}{\mathbb{R}}
\newcommand{\IZ}{\mathbb{Z}}
\newcommand{\IN}{\mathbb{N}}
\newcommand{\IE}{\mathbb{E}}
\newcommand{\mat}[4]{\begin{array}{cc}#1 & #2 \\#3 & #4 \end{array}}
\newcommand{\matb}[4]{\begin{array}{cc}{\bf #1} & {\bf #2} \\{\bf #3} & {\bf #4} \end{array}}
\newcommand{\med}{\mathrm{med}}
\newcommand{\tr}{\mbox{trace}}
\newcommand{\tra}[1]{\mbox{tr}{\bf #1}}
\newcommand{\var}{\mbox{var}}

\newtheorem{exmp}{Example}

%opening
\title{A tutorial for {\bf blockcluster} R package\\Version 3}
\author{Parmeet Singh Bhatia\\INRIA-Lille, parmeet.bhatia@inria.fr}
\date{}


\begin{document}
\maketitle
\tableofcontents
\begin{abstract}
 {\bf blockcluster} is a newly developed {\bf R} package for co-clustering of binary, contingency, continuous and categorical data. The core library is written in {\bf C++} and
{\bf blockcluster} API acts as a bridge between {\bf C++} core library and {\bf R} statistical computing environment. The package is based on recently 
proposed \cite{Govaert2003},\cite{govaert2008binary},\cite{govaert2010contingency}
latent block models for simultaneous clustering of rows and columns. This tutorial is based on the package version 2. 
\end{abstract}
\section{Introduction}
Cluster analysis is an important tool in a variety of scientific areas such as
pattern recognition, information retrieval, micro-array, data mining, and so
forth. Although many clustering procedures such as hierarchical clustering,
$k$-means or self-organizing maps, aim to construct an optimal partition of
objects or, sometimes, of variables, there are other methods, called block
clustering methods, which consider simultaneously the two sets and organize    
the data into homogeneous blocks. Let $\bx$ denotes a $n\times d$ data matrix defined by
$\bx = \{(x_{ij} ); i \in I \mbox{ and } j \in J\}$, where $I$ is a set of $n$ objects (rows,
observations, cases etc) and $J$ is a set of $d$ variables (columns, attributes etc). The basic
idea of these methods consists in making permutations of objects and variables in
order to draw a correspondence structure on $I \times J$.
 \begin{figure}[h!]
\centering
\includegraphics[width = 100mm]{figs/binarysamplecocluster.png}
\caption{Binary data set (a), data reorganized by a partition on $I$ (b), by partitions on $I$ and $J$ simultaneously (c) and summary matrix (d).}
\label{fig:samplecoclust}
\end{figure}
For illustration, consider Figure~\ref{fig:samplecoclust} where a binary data set defined on set of $n=10$ individuals $I = {A,B,C,D,E,F,G,H,I,J}$ and set of
$d=7$ binary variables $J = {1,2,3,4,5,6,7}$ is re-organized into a set of $3\times3$ clusters by permuting the rows and columns. 

Owing to ever increasing importance of Co-clustering in variety of scientific areas, we have recently developed a R package for the same 
called {\bf blockcluster}.
The R package {\bf blockcluster} allows to estimate the parameters of the co-clustering models [\cite{Govaert2003}] for binary,
contingency, continuous and categorical data. This package  is unique from the point of view of generative models it implements
(latent block models), the used algorithms (BEM, BCEM) and, apart from that, special attention has been given
to design the library for handling very huge data sets in reasonable time. The R package is already available on
CRAN at \url{http://cran.r-project.org/web/packages/blockcluster/index.html}. 

This aim of this tutorial is to elaborate the usage of R package {\bf blockcluster} and to familiarize its users with its various capabilties. The rest of the article
is organized as follows. Section \ref{sec:usingblockcluster} gives various details of the package as well as demonstrate it's usage on similated binary data-set.
Section \ref{sec:applications} provides two examples with real data-sets.  

\section{Package details}
\label{sec:usingblockcluster}
This package contains two main functions namely {\bf cocluster} and {\bf cocluststrategy} to perform co-clustering and to set various input parameters respectively. The package also contains two helper functions namely {\bf summary} and {\bf plot} to get the summary of estimated model parameters and to plot the results respectively. We will first go through the details of two main functions. The helper functions are self-explanatory and I will use them in various examples for better understanding.

\subsection{cocluster function}
This is the main function of {\bf blockcluster} package that performs Co-clustering for binary, contingency and continuous data. The prototype
of the function is as follows:\\ \\
\textit{\textbf{cocluster(data, datatype, semisupervised = FALSE, rowlabels = numeric(0), collabels = numeric(0), model = character(0), 
nbcocluster, strategy = cocluststrategy())} }\\ \\
The various inputs of {\bf cocluster} functions are as follows:
\begin{itemize}
\item {\bf data:} Input data as matrix (or list containing data matrix, numeric vector for row effects and numeric  
vector column effects in case of contingency data with known row and column effects.)
\item {\bf datatype:} This is the type of data which can be "binary" , "continuous" or "contingency".
\item {\bf semisupervised:} Boolean value specifying whether to perform semi-supervised co-clustering or not. Make sure to provide row and/or 
column labels if specified value is true. The default value is false.
\item {\bf rowlabels:} Vector specifying the class of rows. The class number starts from zero. Provide -1 for unknown row class. 
\item {\bf collabels:} Vector specifying the class of columns. The class number starts from zero. Provide -1 for unknown column class.
\item {\bf model:} This is the name of model. The various models that are available in package are given in Table~\ref{tab:modeltypes}.
\item {\bf nbcocluster:} Integer vector specifying the number of row and column clusters respectively. 
\item {\bf strategy:} This input can use to control various input parameters. It can be created using the function {\bf cocluststrategy} as explained in Section~\ref{sec:cocluststrategy}.

\end{itemize}
The only mandatory inputs to the function {\bf cocluster} are {\bf data}, {\bf datatype} and {\bf nbcocluster}. The default model for each data-type is the most general model with free row and column proportions and unequal dispersion/variance for each block. Furthermore we have default set of input parameters which works well in most cases which are explained in further details in Section~\ref{sec:cocluststrategy}. The package also comes with OpenMP support (If supported by your Operating system and R). OpenMP will automatically set the number of threads depending on your system. 

\begin{table}[h!]
\centering
 \begin{tabular}{|c|c|c|c|c|}
\hline
     Model  & Datatype & Proportions & Dispersion/Variance & Initialization\\
\hline
     {\bf pik\_rhol\_epsilonkl} & binary & unequal & unequal & CEM\\
     {\bf pik\_rhol\_epsilon} & binary & unequal & equal & CEM\\
     {\bf pi\_rho\_epsilonkl} & binary & equal & unequal & CEM\\
     {\bf pi\_rho\_epsilon} & binary & equal & equal & CEM\\
     {\bf pik\_rhol\_sigma2kl} & continuous & unequal & unequal & CEM\\
     {\bf pik\_rhol\_sigma} & continuous & unequal & equal & CEM\\
     {\bf pi\_rho\_sigma2kl} & continuous & equal & unequal & CEM\\
     {\bf pi\_rho\_sigma2} & continuous & equal & equal & CEM\\
     {\bf pik\_rhol\_unknown} & contingency & unequal & N.A & CEM\\
     {\bf pi\_rho\_unknown} & contingency & equal & N.A & CEM\\
     {\bf pik\_rhol\_known} & contingency & unequal & N.A & Random\\
     {\bf pi\_rho\_known} & contingency & equal & N.A & Random\\
     {\bf pik\_rhol\_multi} & categorical & unequal & N.A & Random\\
     {\bf pi\_rho\_multi} & categorical & equal & N.A & Random\\
\hline
 \end{tabular}
\caption{Various models available in package {\bf blockcluster}.}
\label{tab:modeltypes}
\end{table}


\subsection{cocluststrategy function}
\label{sec:cocluststrategy}
In the package {\bf blockcluster}, we have a function called {\bf cocluststrategy} which can be used to set the values of various input parameters.
The prototype of the function is as follows:
\\ \\\textit{\textbf{cocluststrategy(algo = "BEM", initmethod = character(), stopcriteria = "Parameter", semisupervised = FALSE, nbiterationsxem = 50, 
nbiterationsXEM = 500, nbinititerations = 10, initepsilon = 0.01, nbiterations\_int = 5, epsilon\_int = 0.01, epsilonxem = 1e-04, epsilonXEM = 1e-10, nbtry = 2,
    nbxem = 5,bayesianform = FALSE, hyperparam = numeric(0))}}\\ \\ 
In the following example, we call the function {\bf cocluststrategy} without any arguments and
then we called the overloaded function {\bf summary} to see default values of various input parameters. 
\begin{lstlisting}
R > defaultstrategy <- cocluststrategy()
R > summary(defaultstrategy)

******************************************************************
Algorithm:  BEM
Initialization method(There is no default value):  
Stopping Criteria:  Parameter

Various Iterations
******************
Number of global iterations while running initialization:  10
Number of iterations for internal E-step:  5
Number of EM iterations used during xem:  50
Number of EM iterations used during XEM:  500
Number of xem iterations:  5
Number of tries:  2

Various epsilons
****************
Tolerance value used while initialization:  0.01
Tolerance value for internal E-step:  0.01
Tolerance value used during xem:  1e-04
Tolerance value used during XEM:  1e-10
Bayesian form:  FALSE
Hyper-parameters:  
******************************************************************

\end{lstlisting}
One thing which is worth noting in the summary output (above) is that there is no default value for initialization method. 
It will be set automatically depending on the type of input model. 
To set these input parameters, we have to pass appropriate arguments to function {\bf cocluststrategy} as shown in example 
below where we set {\bf nbtry}, {\bf nbxem} and {\bf algo} parameters. 
\begin{lstlisting}
R > newstrategy <- cocluststrategy(nbtry=5, nbxem=10, algo='BCEM')
\end{lstlisting}
The {\bf newstrategy} object can then be passed to function {\bf cocluster} to perform Co-clustering using the newly set input parameters.
The various input arguments for the function {\bf cocluststrategy} are as follows:
\begin{itemize}
\item {\bf algo:} The valid values for this parameter are "BEM" (Default), "BCEM" and "BSEM" which are respectively Block EM, Block Classifiaction EM and Block
Stochastic EM algorithms.
\item {\bf stopcriteria:} It specifies the stopping criteria. It can be based on either relative change in parameters value (preferred) or relative 
change in log-likelihood. Valid criterion values are "Parameter" and "Likelihood". Default criteria is "Parameter".
\item{\bf initmethod:} Method to initialize model parameters. The valid values are "CEMInit", "FuzzyCEMInit" and "RandomInit". For now only one kind of 
initialization exist for every model currently available in the package. Hence default value for initialization is set according to the model.
\item{\bf nbinititerations:} Number of Global iterations used in initialization step. Default value is 10.
\item{\bf initepsilon:} Tolerance value used inside initialization. Default value is 1e-2.
\item{\bf nbiterations\_int:} Number of iterations for internal E step. Default value is 5.
\item{\bf epsilon\_int:} Tolerance value for relative change in Parameter/likelihood for internal E-step. Default value is 1e-2.
\item{\bf nbtry:} Number of tries (XEM steps). Default value is 2.
\item{\bf nbxem:} Number of xem steps. Default value is 5.
\item{\bf nbiterationsxem:} Number of EM iterations used during xem step. Default value is 50.
\item{\bf nbiterationsXEM:} Number of EM iterations used during XEM step. Deafault value is 500.
\item{\bf epsilonxem:} Tolerance value used during xem step. Default value is 1e-4.
\item{\bf epsilonXEM:} Tolerance value used during XEM step. Default value is 1e-10.
\end{itemize}
To understand many of the above input parameters, we need to have some basic idea about
the algorithms and the way they are run inside package {\bf blockcluster}, which is why there is a separate dedicated 
section ~\ref{sec:inputarguments} for the same.

\subsubsection{Understanding various input parameters}
\label{sec:inputarguments}
You might be wondering why there are so many types of iterations and tolerances inside the package. Well, to get some basic understanding about various input parameters, it is important to know a bit about the algorithms. We will not go through full fledged theory of these algorithms here but will provide enough details to make you understand the meaning of all the input parameters. From now on everything will be explained using BEM but it is applicable in same way to BCEM as well as to BSEM algorithm. The BEM algorithm can be defined as follows in laymen language.
\begin{enumerate}
 \item Run EM algorithm on rows. 
\item Run EM algorithm on columns.
\item Iterate between above two steps until convergence.
\end{enumerate}
The following strategy is employed to run various algorithms.
\begin{enumerate}
\item Run the BEM Algorithm for {\bf 'nbxem'} number of times (with high tolerance and low number of iterations) and keep the best model
parameters (based on likelihood) among these runs. We can this step as {\bf 'xem'} step.
\item Starting with the  best model parameters, run the algorithm again but this time with a low value of epsilon (low tolerance) 
and a high number of iterations. We can this step as {\bf 'XEM'} step.
\item Repeat above two steps for {\bf 'nbtry'} number of times and keep the best model estimation.
\end{enumerate}
With this background, the various input parameters are explained as follows. 
\begin{itemize}
 \item {\bf nbxem, nbtry:} As explained above these numbers represents the number of time we run {\bf 'xem'} step and {\bf 'xem'+'XEM'} step respectively.
The tuning of the values of {\bf 'nbxem'} and {\bf 'nbtry'} 
need to be done intuitively, and could have a substantial effect on final results. A good way to set these values
is to run co-clustering few number of times and check if final log-likelihood is stable. If not, one may need to increase these values.
In practice, it is better to
increment {\bf 'nbxem'} as it could lead to better (stable) results without compromising too much the running time.
\item {\bf nbiterationsxem, nbiterationsXEM:} These are number of iterations for BEM algorithm i.e the number of times we run EM on rows and EM on columns. As the 
name suggests, they are respectively for {\bf 'xem'} and {\bf 'XEM'} steps. 
\item {\bf nbiterations\_int:} This is the number of iterations for EM algorithm on rows/columns.
\item {\bf epsilonxem, epsilonXEM:} These are tolerance values for BEM algorithm during {\bf 'xem'} and {\bf 'XEM'} step respectively. 
\item {\bf epsilon\_int:} This is the tolerance value for EM algorithm on rows/columns.
\item {\bf initepsilon, nbinititerations:} These are the tolerance value and number of iterations respectively used during initialization of model parameters.
\item {\bf bayesianform:} Boolean parameter to indicate whether to run algorithms in bayesian settings or not. Algorithms under bayesian settings are currently only implemented for binary and categorical models. Default value is false.
\item {\bf hyperparam: } Hyper-parameters ("a" and "b") in case of Bayesian settings. If the assigned value of "a" and "b" is 1, then the algorithms are no different than their original form.  
\end{itemize}

\subsection{Model Parameters}
When {\bf summary} function is called on the output {\bf cocluster} fuction, it gives the estimated values of various model parameters. The parameters that are common among all the models are row and column mixing proportions. The model parameter for various data-types are as follows.\\\\
{\bf Binary Models}\\
The parameters $\balpha$ of the underlying distribution of a binary data set is given
by the matrix $\bp=(p_{k\ell})$ where $p_{k\ell} \in
]0,1[$ $\forall$ $k=1,\ldots,g$ and $\ell=1,\ldots,m$ and the probability distribution $f_{k\ell}(x_{ij};\bp)=f(x_{ij};p_{k\ell})$ is the Bernoulli
distribution $$f(x_{ij};p_{k\ell})=(p_{k\ell})^{x_{ij}}(1-p_{k\ell})^{1-x_{ij}}.$$
we re-parameterize the model density as follows:
$$f_{k\ell}(x_{ij};\balpha)=(\varepsilon_{kj})^{|x_{ij}-a_{k\ell}|}
(1-\varepsilon_{kj})^{1-|x_{ij}-a_{k\ell}|}$$
where
$$\left\{
  \begin{array}{ll}
    a_{k\ell}=0, \; \varepsilon_{k\ell}=p_{k\ell} &\mbox{ if } p_{k\ell}<0.5\\
    a_{k\ell}=1, \; \varepsilon_{k\ell}=1-p_{k\ell} &\mbox{ if } p_{k\ell}>0.5.
  \end{array}
\right.
$$

Hence the parameters $p_{k\ell}$ of the Bernoulli mixture model are replaced by the following parameters:
\begin{itemize}
\item The binary value $a_{k\ell}$, which acts as the center of the block $k,\ell$ and which
  gives, for each block, the most frequent binary value,
\item The value $\varepsilon_{k\ell}$ belonging to the set $]0,1/2[$ that characterizes the dispersion of the block $k,\ell$
  and which is, for each block, represents the probability of having a different value than the center.
\end{itemize}
{\bf Continuous Models}\\
In this case, the continuous data is modeled using unidimensional normal distribution. Hence the density for each block is given by:
$$f_{k\ell}(x_{ij};\balpha)= \frac{1}{\sqrt{2\pi\sigma_{k\ell}^2}}\exp-\{\frac{1}{2\sigma_{k\ell}^2}(x_{ij}-\mu_{k\ell})^2\}$$
The parameters of the model are $\balpha=(\balpha_{11},\ldots,\balpha_{gm})$ where $\balpha_{k\ell}=(\mu_{k\ell},\sigma^2_{k\ell})$ i.e the mean and variance of block $k,l$.\\\\
{\bf Contingency Models}\\
In this case, it is assumed that for each block
$k,\ell$, the values $x_{ij}$ are distributed according to Poisson distribution
$\mathcal{P}(\mu_i \nu_j \gamma_{k\ell})$ where the Poisson parameter is split into $\mu_i$ and
$\nu_j$ the effects of the row $i$ and the column $j$ respectively and $\gamma_{k\ell}$ the effect of the
block $k\ell$. Then, we have
$$f_{k\ell}(x_{ij};\balpha)=
\frac{e ^{-\mu_i \nu_j \gamma_{k\ell}} (\mu_i \nu_j \gamma_{k\ell})^{x_{ij}}}{x_{ij}!}$$
where $\balpha=(\bmu,\bnu,\bgamma)$ with $\bmu=(\mu_1,\ldots,\mu_n)$,
$\bnu=(\bnu_1,\ldots,\nu_d)$ and $\bgamma=(\gamma_{11},\ldots,\gamma_{gm})$.
The row and column effects are either provided by the user for models {\bf pik\_rhol\_known}  and {\bf pi\_rho\_known}  or estimated by the package itself for models {\bf pik\_rhol\_unknown} and {\bf pi\_rho\_unknown}.\\\\
{\bf Categorical Models}\\
The idea behind categorical models is simple extension of binary models for more than 2 modalities. Hence instead of Bernoulli distribution, we used Multinomial (categorical) distribution. Hence the model parameters for each block $k,l$ are $\balpha_{k\ell}=(\balpha_{k\ell}^{h})_{h=1,..r}$ and $\sum_h{\balpha_{k\ell}^{h}}=1$ where $r$ is the number of modalities. 

\subsection{Example using simulated Binary dataset}
The various parameters used to simulate this binary data-set are given in Table~\ref{tab:binarytableparam}. The class mean and dispersion are respectively represented by $\ba$ and $\bepsilon$ whereas $\bpi$ and $\brho$ represents row and column proportions respectively. The data consist of $1000$ rows (samples) and $100$ columns (variables) with two clusters on rows and three clusters on columns. The following R commands shows how to load the library, process the data and visualize/summarize results using {\bf blockcluster}.
\begin{table}[h!]
\begin{minipage}{.59\linewidth}
 \flushright
\begin{tabular}{|c|c|c|c|}
\hline
\multirow{2}{1cm}{$\ba$, $\bepsilon$}&0, 0.1&0, 0.3&1, 0.1\\
\cline{2-4}
&1, 0.3&1, 0.2&0, 0.1\\
\hline
\end{tabular}
\end{minipage}
\begin{minipage}{.39\linewidth}
 \flushleft
\begin{tabular}{|c|c|c|}
 \hline
$\bpi$&.6&.4\\
\hline
\end{tabular} \\
\begin{tabular}{|c|c|c|c|}
\hline
$\brho$&.3&.3&.4\\
\hline
\end{tabular}
\end{minipage}
\caption{Parameters for simulation of binary data.}
\label{tab:binarytableparam}
\end{table}
\begin{figure}[h!]
\begin{minipage}{.4\linewidth}
 \includegraphics[width = 55mm,height=80mm]{figs/coclustbinary1.jpg}\\
\centering(a)
\end{minipage}
\begin{minipage}{.59\linewidth}
 \includegraphics[width = 75mm,height=80mm]{figs/distributionbinary.jpeg}\\
\centering(b)
\end{minipage}
\caption{Original and co-clustered binary data (a), and distributions for each block along with various mixture densities (b).}
\label{fig:binarydata}
\end{figure}

\begin{lstlisting}
R > library("blockcluster")
R > data("binarydata")
R > out<-cocluster(binarydata, datatype = "binary", nbcocluster=c(2,3))
R > summary(out)
******************************************************************
Model Family : Bernoulli Latent block model
Model Name : pik_rhol_epsilonkl
Co-Clustering Type : Unsupervised
ICL value:  -45557.09

Model Parameters..

Class Mean:
     [,1] [,2] [,3]
[1,]    0    0    1
[2,]    1    0    0

Class Dispersion:
          [,1]       [,2]      [,3]
[1,] 0.1006313 0.30176929 0.2003679
[2,] 0.1011803 0.09798013 0.3022391

Row proportions:  0.382 0.618
Column proportions:  0.34 0.29 0.37
Pseudo-likelihood:  -0.4552042
******************************************************************

\end{lstlisting}

Note that you also get the Integrated complete likelihood (ICL) value in case binary and categorical models. This value can be used for model selection. The following {\bf R} command is used to plot the original and co-clustered data (Figure~\ref{fig:binarydata}(a)) with default value of {\bf asp} which is $0$ (FALSE). When {\bf asp} is FALSE, R graphics will optimize the output figure for the display, hence the original aspect ratio may 
not be conserved. To conserve the original aspect ratio, set the value of {\bf asp} as $1$ or TRUE.
\begin{lstlisting}
R > plot(out, asp = 0)
\end{lstlisting}
To Plot various block distributions (Figure~\ref{fig:binarydata}(b)), the following {\bf R} command is used with
{\bf type} argument of overloaded {\bf plot} function set to 'distribution' ({\bf type} is 'cocluster' by default which plots the original and Co-clustered
data as shown in (Figure~\ref{fig:binarydata}(a))).
\begin{lstlisting}
R > plot(out, type = 'distribution')
\end{lstlisting}
\section{Examples with real datasets}
\label{sec:applications}
This section  demonstrates the applicability of package on real data. Two examples are used: one for Image 
segmentation and other for document (co-)clustering. 

\subsection{Image segmentation}

Automatic image segmentation is an important technique and have numerous application especially in fields of Medical imaging. Here I present an interesting
application of co-clustering (as pre-processing step) for segmenting object(s) in image. I assume that the object pixels follows Gaussian distribution. 
Hence I run the {\bf blockcluster} package with Gaussian Family model {\bf pik\_rhol\_sigma2kl}  on image shown in Figure~\ref{fig:coclustersnake}.
It can be clearly seen that the image got nicely segmented into snake and insect in two different blocks. 

\begin{figure}[ht]
\centering
 \includegraphics[scale=.25]{figs/coclustersnake.jpg}
\caption{Original and co-clustered (segmented) image.}
\label{fig:coclustersnake}
\end{figure}
 % and in particular Gaussian latent block model used in our software.

\subsection{Document clustering}

Document clustering is yet another data mining technique where co-clustering seems to be very useful. Here we run our
package on one of the datasets being used in \cite{Dhillon01} which is publicly available at \url{ftp://ftp.cs.cornell.edu/pub/smart}. We mix Medline 
(1033 medical abstracts)
and Cranfield (1398 aeronautical abstracts) making a total of 2431 documents. Furthermore, we used all the words (excluding stop words) as features making
a total of $9275$ unique words. The data matrix consist of words on the rows and documents on the columns with each entry giving
the term frequency, that is the number of occurrences of corresponding word in corresponding document. I assume that the term frequency
follows Poisson distribution. Hence we can apply the model {\bf pik\_rhol\_unknown}  available in our package for contingency (Poisson Family) 
datasets with unknown row and column effects. Table~\ref{tab:confusionmatrix} shows the confusion
 matrix
and compare our results with classical bipartite spectral graph partitioning algorithm of [\cite{Dhillon01}] where we have obtained $100$ percent correct classification.
Figure~\ref{fig:coclusterdocument} depicts 
the $2\times2$ checkerboard pattern in the data matrix, hence confirming the more frequent occurrence of
particular set of words in one document and vice-versa. Please note that the data matrix images are extremely sparse (data points almost invisible) 
and have been processed using simple image processing tools for visualization purpose only.

\begin{table}[h!]
\begin{minipage}{.49\linewidth}
 \centering
\begin{tabular}{c|c|c|}
\cline{2-3}
&Medline&Cranfield\\
\hline
\multicolumn{1}{|c|}{Medline}&1026&0\\
\hline
\multicolumn{1}{|c|}{Cranfield}&7&1400\\
\hline
\end{tabular}\\
\vspace{.1cm}
(a)
\end{minipage}
\begin{minipage}{.49\linewidth}
 \centering
\begin{tabular}{c|c|c|}
\cline{2-3}
&Medline&Cranfield\\
\hline
\multicolumn{1}{|c|}{Medline}&1033&0\\
\hline
\multicolumn{1}{|c|}{Cranfield}&0&1398\\
\hline
\end{tabular}\\
\vspace{.1cm}
(b)
\end{minipage}
\caption{Confusion Matrix: Results reported in \cite{Dhillon01} (a), and Results using {\bf blockcluster} (b). The difference in number
of Cranfield documents is because we made use of the already available data extracted from the documents and there are two less documents data in the same.} 
\label{tab:confusionmatrix}
\end{table}


\begin{figure}[h!]
\begin{minipage}{.49\linewidth}
\centering
\begin{sideways}Unique Words \end{sideways}
\begin{tikzpicture}
\draw[black,
    decoration={markings,mark=at position 1 with {\arrow[scale=2,black]{>}}},
    postaction={decorate},
    shorten >=0.4pt
    ]
    (1.0,0) -- (1.0,4);
\end{tikzpicture}
\hspace{.2cm}
 \includegraphics[width = 25mm,height=60mm]{figs/orgdata.jpg}\\
\begin{tikzpicture}
\draw[black,
    decoration={markings,mark=at position 1 with {\arrow[scale=2,black]{>}}},
    postaction={decorate},
    shorten >=0.4pt
    ]
    (1.0,5) -- (3.0,5);
\end{tikzpicture}\\
Documents\\
\vspace{.1cm}
(a)
\end{minipage}
\begin{minipage}{.49\linewidth}
\centering
\begin{sideways}Unique Words \end{sideways}
\begin{tikzpicture}
\draw[black,
    decoration={markings,mark=at position 1 with {\arrow[scale=2,black]{>}}},
    postaction={decorate},
    shorten >=0.4pt
    ]
    (1.0,0) -- (1.0,4);
\end{tikzpicture}
\hspace{.2cm}
 \includegraphics[width = 25mm,height=60mm]{figs/coclustdata.jpg}\\
\begin{tikzpicture}
\draw[black,
    decoration={markings,mark=at position 1 with {\arrow[scale=2,black]{>}}},
    postaction={decorate},
    shorten >=0.4pt
    ]
    (0,5) -- (2,5);
\end{tikzpicture}\\
Documents\\
\vspace{.1cm}
(b)
\end{minipage}
\caption{Original data matrix with words on rows and documents on columns (a), and checkerboard pattern in words by documents matrix obtained after performing
co-clustering (b).}
\label{fig:coclusterdocument}
\end{figure}

\section{Remarks}
This tutorial gives a brief introduction about the {\bf blockcluster} R package. It demonstrates the use of package using Binary data-set but the package can be used in similar fashion for other types of data namely {\bf Contingency}, {\bf Continuous} and {\bf Categorical}. Please note that this tutorial is based on version 3. If you have any questions,suggestions or remarks, do not hesitate to put it on public forum at \url{https://gforge.inria.fr/forum/forum.php?forum_id=11190&group_id=3679}.


\bibliographystyle{plain}
\bibliography{biblio.bib}
\end{document}
